<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SemGes: Semantic-Aware Gesture Generation</title>

    <!-- Swiper.js CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@9/swiper-bundle.min.css">

    <style>
        @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400;700&display=swap');

        body {
            font-family: 'Playfair Display', serif;
            font-size: 18px;
            margin-left: auto;
            margin-right: auto;
            width: 1100px;
            background-color: #f9f9f9;
        }

        h1 {
            font-size: 36px;
            font-weight: 700;
            text-align: center;
            color: #333;
        }

        /* Swiper styles */
        .swiper-container {
            width: 100%;
            max-width: 900px;
            margin: auto;
            padding-top: 20px;
            padding-bottom: 40px;
        }

        .swiper-slide {
            display: flex;
            justify-content: center;
            align-items: center;
            background: #fff;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.2);
        }

        video {
            width: 100%;
            max-width: 600px;
            border-radius: 12px;
            border: 2px solid #ccc;
        }

        .video-caption {
            text-align: center;
            font-size: 16px;
            color: #555;
            font-style: italic;
            margin-top: 5px;
        }

        .content {
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1);
            margin-top: 20px;
        }
    </style>
</head>
<body>

    <br>
    <center>
        <h1>SemGes: Semantic-Aware Gesture Generation</h1>
    </center>

    <!-- Swiper for videos (above abstract) -->
    <div class="swiper-container swiper">
        <div class="swiper-wrapper">
            <div class="swiper-slide">
                <video controls>
                    <source src="video1.mp4" type="video/mp4">
                </video>
            </div>
            <div class="swiper-slide">
                <video controls>
                    <source src="video2.mp4" type="video/mp4">
                </video>
            </div>
            <div class="swiper-slide">
                <video controls>
                    <source src="video3.mp4" type="video/mp4">
                </video>
            </div>
        </div>
        <!-- Pagination & navigation -->
        <div class="swiper-pagination"></div>
        <div class="swiper-button-prev"></div>
        <div class="swiper-button-next"></div>
    </div>

    <div class="video-caption">Figure 1: Example of generated gestures from our model.</div>

    <div class="content">
        <h1>Abstract</h1>
        <p>
            Creating a virtual avatar with semantically coherent gestures that are aligned with speech is a challenging task.
            Existing gesture generation research mainly focused on generating rhythmic beat gestures, neglecting the semantic context of the gestures.
            In this paper, we propose a novel approach for semantic grounding in co-speech gesture generation that integrates semantic information at both fine-grained and global levels.
            Our approach starts with learning the motion prior through a vector-quantized variational autoencoder. Built on this model, a second-stage module is applied to automatically generate gestures from speech, text-based semantics, and speaker identity that ensures consistency between the semantic relevance of generated gestures and co-occurring speech semantics through semantic coherence and relevance modules.
            Experimental results demonstrate that our approach enhances the realism and coherence of semantic gestures.
            Extensive experiments and user studies show that our method outperforms state-of-the-art approaches across two benchmarks in co-speech gesture generation in both objective and subjective metrics.
        </p>
    </div>

    <!-- Swiper for videos (below abstract) -->
    <div class="swiper-container swiper">
        <div class="swiper-wrapper">
            <div class="swiper-slide">
                <video controls>
                    <source src="video4.mp4" type="video/mp4">
                </video>
            </div>
            <div class="swiper-slide">
                <video controls>
                    <source src="video5.mp4" type="video/mp4">
                </video>
            </div>
            <div class="swiper-slide">
                <video controls>
                    <source src="video6.mp4" type="video/mp4">
                </video>
            </div>
        </div>
        <!-- Pagination & navigation -->
        <div class="swiper-pagination"></div>
        <div class="swiper-button-prev"></div>
        <div class="swiper-button-next"></div>
    </div>

    <div class="video-caption">Figure 2: Additional examples demonstrating semantic-aware gestures.</div>

    <!-- Swiper.js Script -->
    <script src="https://cdn.jsdelivr.net/npm/swiper@9/swiper-bundle.min.js"></script>
    <script>
        var swiper = new Swiper(".swiper", {
            slidesPerView: 1,
            spaceBetween: 10,
            loop: true,
            navigation: {
                nextEl: ".swiper-button-next",
                prevEl: ".swiper-button-prev",
            },
            pagination: {
                el: ".swiper-pagination",
                clickable: true,
            },
        });
    </script>

</body>
</html>
